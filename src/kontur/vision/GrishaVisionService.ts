/**
 * GrishaVisionService - Unified Vision Service for Grisha
 * 
 * Supports both modes:
 * - LIVE: Continuous streaming to Gemini Live (real-time observation)
 * - ON-DEMAND: Screenshot after each step, analyzed by Copilot/GPT-4o
 * 
 * Both modes share the same interface for window selection and verification
 */

import { EventEmitter } from 'events';
import { desktopCapturer } from 'electron';
import { getVisionConfig } from '../providers/config';
import { getProviderRouter } from '../providers/router';
import { VisionResponse } from '../providers/types';

export interface VisionObservationResult {
    type: 'confirmation' | 'alert' | 'observation' | 'verification';
    message: string;
    verified?: boolean; // For on-demand: did the task succeed?
    confidence?: number;
    anomalies?: Array<{
        type: string;
        severity: 'low' | 'medium' | 'high';
        description: string;
    }>;
    timestamp: number;
    mode: 'live' | 'on-demand';
}

export interface ScreenSource {
    id: string;
    name: string;
    thumbnail: string;
    isScreen: boolean;
}

export class GrishaVisionService extends EventEmitter {
    private isObserving: boolean = false;
    private isPaused: boolean = false;
    private captureInterval: NodeJS.Timeout | null = null;
    private captureIntervalMs: number = 2000; // 2s = 0.5 FPS (optimized for API)
    private geminiLive: any = null;
    private frameCount: number = 0;
    private isSpeaking: boolean = false;

    // Selected source for capture
    private selectedSourceId: string | null = null;
    private selectedSourceName: string | null = null;

    constructor() {
        super();
    }

    /**
     * Get current Vision mode from config
     */
    get mode(): 'live' | 'on-demand' {
        return getVisionConfig().mode;
    }

    /**
     * Set Gemini Live service (for live mode)
     */
    setGeminiLive(geminiLive: any) {
        this.geminiLive = geminiLive;

        if (geminiLive) {
            geminiLive.on('text', (text: string) => {
                this.processLiveResponse(text);
            });

            geminiLive.on('audio', (audio: any) => {
                if (!this.isSpeaking) {
                    this.isSpeaking = true;
                    console.log('[GRISHA VISION] üîá Audio started - pausing frame capture');
                    setTimeout(() => {
                        if (this.isSpeaking) {
                            console.log('[GRISHA VISION] ‚è±Ô∏è Audio timeout - resuming');
                            this.isSpeaking = false;
                        }
                    }, 5000);
                }
                this.emit('audio', audio);
            });

            geminiLive.on('turnComplete', () => {
                console.log('[GRISHA VISION] üé§ Turn complete');
                this.isSpeaking = false;
                this.emitResult('confirmation', 'Grisha finished speaking', true);
            });
        }
    }

    /**
     * Get available screen/window sources
     */
    async getSources(): Promise<ScreenSource[]> {
        try {
            const sources = await desktopCapturer.getSources({
                types: ['window', 'screen'],
                thumbnailSize: { width: 150, height: 100 }
            });

            return sources.map(source => ({
                id: source.id,
                name: source.name,
                thumbnail: source.thumbnail.toDataURL(),
                isScreen: source.id.startsWith('screen:')
            }));
        } catch (err) {
            console.error('[GRISHA VISION] Failed to get sources:', err);
            return [];
        }
    }

    /**
     * Select a specific source (window/screen) for capture
     */
    selectSource(sourceId: string, sourceName: string) {
        this.selectedSourceId = sourceId;
        this.selectedSourceName = sourceName;
        console.log(`[GRISHA VISION] üéØ Selected source: ${sourceName} (${sourceId})`);
        this.emit('source_changed', { id: sourceId, name: sourceName });
    }

    /**
     * Helper: Find window TITLE via generic AppleScript
     * This bridges the gap between App Name (known by user) and Window Title (known by desktopCapturer)
     */
    private async findWindowTitleForApp(appName: string): Promise<string | null> {
        const script = `
        tell application "System Events"
            try
                set targetApp to process "${appName}"
                if not (exists targetApp) then return ""
                if (count of windows of targetApp) is 0 then return ""
                
                set winTitle to name of window 1 of targetApp
                return winTitle
            on error
                return ""
            end try
        end tell
        `;

        try {
            const { exec } = require('child_process');
            const result: string = await new Promise((resolve) => {
                exec(`osascript -e '${script}'`, (err: any, stdout: string) => {
                    if (err) resolve("");
                    else resolve(stdout.trim());
                });
            });

            return result || null;
        } catch (e) {
            console.warn(`[GRISHA VISION] AppleScript Lookup Failed for ${appName}:`, e);
            return null;
        }
    }

    /**
     * Auto-select source by app name
     */
    async autoSelectSource(appName: string): Promise<boolean> {
        const sources = await this.getSources();

        // Debug: List all available windows for troubleshooting
        const externalSources = sources.filter(s =>
            !s.name.toLowerCase().includes('electron') &&
            !s.name.toLowerCase().includes('atlas') &&
            !s.name.toLowerCase().includes('kontur')
        );

        console.log(`[GRISHA VISION] üîç Looking for "${appName}" among ${externalSources.length} external windows`);

        if (externalSources.length === 0) {
            console.log('[GRISHA VISION] ‚ö†Ô∏è No external windows found via desktopCapturer.');
        } else {
            console.log('[GRISHA VISION] üìã Available Windows: ' + externalSources.map(s => `"${s.name}"`).join(', '));
        }

        const normalize = (s: string) => s.toLowerCase().trim().replace(/[\u2013\u2014]/g, "-");
        const target = normalize(appName);

        // Common mappings (UA <-> EN)
        const ALIASES: Record<string, string[]> = {
            '–∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä': ['Calculator'],
            'calculator': ['Calculator'],
            '—Ç–µ—Ä–º—ñ–Ω–∞–ª': ['Terminal', 'iTerm2'],
            'terminal': ['Terminal', 'iTerm2'],
            '–Ω–æ—Ç–∞—Ç–∫–∏': ['Notes'],
            'notes': ['Notes'],
            '—Å–∞—Ñ–∞—Ä—ñ': ['Safari'],
            'safari': ['Safari'],
            '—Ñ–∞–π–Ω–¥–µ—Ä': ['Finder'],
            'finder': ['Finder'],
            'chrome': ['Google Chrome'],
            'google chrome': ['Google Chrome'],
            'code': ['Code', 'Visual Studio Code'],
            'vscode': ['Code', 'Visual Studio Code']
        };

        const potentialAppNames = [appName, ...(ALIASES[target] || [])];

        // --- STRATEGY 1: AppleScript Title Lookup (Most Accurate) ---
        // Get the Window Title from the OS for the given App, then find source with that Title
        for (const name of potentialAppNames) {
            const trueWindowTitle = await this.findWindowTitleForApp(name);
            if (trueWindowTitle) {
                console.log(`[GRISHA VISION] üçè AppleScript found Title "${trueWindowTitle}" for app "${name}"`);

                const exactMatch = externalSources.find(s => normalize(s.name) === normalize(trueWindowTitle));

                if (exactMatch) {
                    console.log(`[GRISHA VISION] ‚úÖ Exact Title Match: "${exactMatch.name}"`);
                    this.selectSource(exactMatch.id, exactMatch.name);
                    return true;
                }

                // Partial match on title if exact fails (e.g. specialized chars)
                const partialMatch = externalSources.find(s => normalize(s.name).includes(normalize(trueWindowTitle)) || normalize(trueWindowTitle).includes(normalize(s.name)));
                if (partialMatch) {
                    console.log(`[GRISHA VISION] ‚úÖ Partial Title Match: "${partialMatch.name}" matches "${trueWindowTitle}"`);
                    this.selectSource(partialMatch.id, partialMatch.name);
                    return true;
                }
            }
        }

        // --- STRATEGY 2: Fuzzy Title Matching (Fallback) ---
        console.log(`[GRISHA VISION] ‚ö†Ô∏è Title Lookup failed, falling back to title matching...`);

        const searchTerms = [target, ...(ALIASES[target] || []).map(s => normalize(s))];

        // 2.1 Exact Title Match
        let matched = externalSources.find(s =>
            searchTerms.some(term => normalize(s.name) === term)
        );

        // 2.2 Starts With
        if (!matched) {
            matched = externalSources.find(s =>
                searchTerms.some(term => normalize(s.name).startsWith(term))
            );
        }

        // 2.3 Contains
        if (!matched) {
            matched = externalSources.find(s =>
                searchTerms.some(term => normalize(s.name).includes(term))
            );
        }

        // 2.4 Word Match
        if (!matched) {
            matched = externalSources.find(s =>
                searchTerms.some(term => {
                    const windowWords = normalize(s.name).split(' ');
                    return windowWords.includes(term);
                })
            );
        }

        if (matched) {
            console.log(`[GRISHA VISION] ‚úÖ Found window via Title: "${matched.name}" (matched for "${appName}")`);
            this.selectSource(matched.id, matched.name);
            return true;
        }

        console.warn(`[GRISHA VISION] ‚ö†Ô∏è Window not found for: "${appName}".`);
        return false;
    }

    /**
     * Clear source selection (capture entire screen)
     */
    clearSourceSelection() {
        this.selectedSourceId = null;
        this.selectedSourceName = null;
        console.log('[GRISHA VISION] üñ•Ô∏è Using full screen capture');
    }

    /**
     * Start observation (works for both modes)
     */
    async startObservation(taskDescription?: string) {
        if (this.isObserving) return;

        const currentMode = this.mode;
        console.log(`[GRISHA VISION] üëÅÔ∏è Starting observation [${currentMode.toUpperCase()}]...`);
        this.isObserving = true;
        this.frameCount = 0;

        // Clear cached source from previous session
        this.selectedSourceId = null;
        this.selectedSourceName = null;

        if (currentMode === 'live') {
            await this.startLiveObservation(taskDescription);
        } else {
            // On-demand: just mark as observing, capture happens per-step
            this.emitResult('observation', `On-Demand —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è –∞–∫—Ç–∏–≤–æ–≤–∞–Ω–æ. ${taskDescription || '–ì–æ—Ç–æ–≤–∏–π –¥–æ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏.'}`);
        }
    }

    /**
     * Stop observation
     */
    stopObservation() {
        if (!this.isObserving) return;

        console.log(`[GRISHA VISION] üëÅÔ∏è Observation stopped after ${this.frameCount} frames`);
        this.isObserving = false;
        this.isSpeaking = false;
        this.isPaused = false;

        if (this.captureInterval) {
            clearInterval(this.captureInterval);
            this.captureInterval = null;
        }

        this.emitResult('confirmation', `–°–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è –∑–∞–≤–µ—Ä—à–µ–Ω–æ. –ü–µ—Ä–µ–≤—ñ—Ä–µ–Ω–æ ${this.frameCount} –∫–∞–¥—Ä—ñ–≤.`);
    }

    /**
     * Pause capture (during step execution)
     */
    pauseCapture() {
        if (!this.isPaused) {
            this.isPaused = true;
            console.log('[GRISHA VISION] ‚è∏Ô∏è Capture paused');
        }
    }

    /**
     * Resume capture (for step verification)
     */
    resumeCapture() {
        if (this.isPaused) {
            this.isPaused = false;
            console.log('[GRISHA VISION] ‚ñ∂Ô∏è Capture resumed');
            // Send immediate frame on resume for verification
            if (this.mode === 'live') {
                this.captureAndSendLiveFrame();
            }
        }
    }

    /**
     * Verify a step was executed (On-Demand mode)
     * Captures screenshot and sends to Copilot/GPT-4o for analysis
     */
    /**
     * Verify a step was executed
     */
    async verifyStep(stepAction: string, stepDetails?: string, globalContext?: string, targetApp?: string): Promise<VisionObservationResult> {
        console.log(`[GRISHA VISION] üîç Verifying step: ${stepAction}`);

        // If ON-DEMAND mode, run directly
        if (this.mode === 'on-demand') {
            return this.verifyStepOnDemand(stepAction, stepDetails, globalContext, targetApp);
        }

        // Live mode with fallback
        return new Promise(async (resolve) => {
            // Notify Gemini Live
            await this.notifyActionLive(stepAction, stepDetails || '');

            const cleanup = () => {
                this.removeListener('observation', responseHandler);
            };

            const responseHandler = (result: VisionObservationResult) => {
                if (result.type === 'confirmation' || result.type === 'alert') {
                    cleanup();
                    resolve(result);
                }
            };

            this.on('observation', responseHandler);

            // Timeout with FALLBACK
            setTimeout(async () => {
                cleanup();
                console.warn('[GRISHA VISION] ‚ö†Ô∏è Verification timeout (Live Mode). Falling back to On-Demand verification...');

                try {
                    // FALLBACK: Try GPT-4o / Copilot analysis as backup
                    const fallbackResult = await this.verifyStepOnDemand(stepAction, stepDetails, globalContext, targetApp);
                    resolve(fallbackResult);
                } catch (e) {
                    resolve({
                        type: 'alert',
                        message: 'Timeout & Fallback Failed: Gemini Live did not respond and On-Demand analysis failed.',
                        verified: false,
                        timestamp: Date.now(),
                        mode: 'live'
                    });
                }
            }, 10000); // 10s timeout before fallback
        });
    }

    /**
     * Check if an object/window is visible on screen
     * Returns visibility check result
     */
    private async checkObjectVisibility(stepAction: string, base64Image: string, explicitTarget?: string): Promise<{ visible: boolean, message: string }> {
        try {
            const router = getProviderRouter();

            // Use explicit target if available, otherwise try to extract
            let objectName = explicitTarget;

            if (!objectName) {
                // Extract object/app name from step action
                const objectMatch = stepAction.match(/(?:–≤—ñ–¥–∫—Ä–∏—Ç–∏|open|launch|–≤ –ø—Ä–æ–≥—Ä–∞–º—ñ|in|—É|click|–Ω–∞—Ç–∏—Å–Ω–∏|type in)\s+([A-Za-z–ê-–Ø–∞-—è—ñ–Ü—ó–á—î–Ñ0-9\s]+)/i);
                objectName = objectMatch
                    ? objectMatch[1].trim()
                    : (this.selectedSourceName || stepAction);
            }

            const visibilityPrompt = `
–ê–ù–ê–õ–Ü–ó –í–ò–î–ò–ú–û–°–¢–Ü:
–ó–∞–≤–¥–∞–Ω–Ω—è: "${stepAction}"
–û–±'—î–∫—Ç/–≤—ñ–∫–Ω–æ –¥–ª—è –ø–æ—à—É–∫—É: "${objectName}"

–í–ê–ñ–õ–ò–í–û:
- –Ü–≥–Ω–æ—Ä—É–π —Ç–µ–∫—Å—Ç–æ–≤—ñ –ª–æ–≥–∏, –∫–æ–Ω—Å–æ–ª—å –∞–±–æ —á–∞—Ç, –¥–µ –Ω–∞–ø–∏—Å–∞–Ω–æ –ø—Ä–æ —Ü–µ–π –æ–±'—î–∫—Ç.
- –¢–∏ –ø–æ–≤–∏–Ω–µ–Ω –±–∞—á–∏—Ç–∏ –°–ê–ú –Ü–ù–¢–ï–†–§–ï–ô–° –ø—Ä–æ–≥—Ä–∞–º–∏ (–∫–Ω–æ–ø–∫–∏, –ø–æ–ª—è, –≤—ñ–∫–Ω–æ).
- –Ø–∫—â–æ —Ç–∏ –±–∞—á–∏—à —Ç—ñ–ª—å–∫–∏ —Ç–µ–∫—Å—Ç "Calculator opened" –∞–±–æ –ø–æ–¥—ñ–±–Ω–µ –≤ –ª–æ–≥–∞—Ö - —Ü–µ invisible.
- –Ø–∫—â–æ –≤—ñ–∫–Ω–æ –ø–µ—Ä–µ–∫—Ä–∏—Ç–æ —ñ–Ω—à–∏–º (–Ω–∞–ø—Ä–∏–∫–ª–∞–¥ ATLAS KONTUR) - —Ü–µ invisible.

–í–Ü–î–ü–û–í–Ü–î–¨ –ù–ê –ü–ò–¢–ê–ù–ù–Ø:
1. –ß–∏ –±–∞—á–∏—à —Ç–∏ –Ü–ù–¢–ï–†–§–ï–ô–° –ø—Ä–æ–≥—Ä–∞–º–∏ "${objectName}"?
2. –Ø–∫—â–æ —Ç–∞–∫ - –æ–ø–∏—à–∏ —è–∫ –≤—ñ–Ω –≤–∏–≥–ª—è–¥–∞—î (–∫–æ–ª—ñ—Ä, –µ–ª–µ–º–µ–Ω—Ç–∏)?
3. –Ø–∫—â–æ –Ω—ñ - —â–æ —Å–∞–º–µ –ø–µ—Ä–µ–∫—Ä–∏–≤–∞—î –π–æ–≥–æ?

–§–æ—Ä–º–∞—Ç –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ JSON:
{
  "visible": true/false,
  "location": "–æ–ø–∏—Å –¥–µ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å—Å—è" –∞–±–æ null,
  "screen_content": "—â–æ –≤–∏–¥–Ω–æ –Ω–∞ –µ–∫—Ä–∞–Ω—ñ",
  "is_obscured_by_atlas": true/false
}`;

            const response = await router.analyzeVision({
                image: base64Image,
                mimeType: 'image/jpeg',
                taskContext: stepAction,
                prompt: visibilityPrompt
            });

            // Parse visibility response
            try {
                const analysis = response.analysis;
                const jsonMatch = analysis.match(/\{[\s\S]*\}/);
                if (jsonMatch) {
                    const parsed = JSON.parse(jsonMatch[0]);
                    const visible = parsed.visible === true;

                    if (visible) {
                        const location = parsed.location || '–Ω–∞ –µ–∫—Ä–∞–Ω—ñ';
                        return {
                            visible: true,
                            message: `–ë–∞—á—É "${objectName}" ${location}`
                        };
                    } else {
                        const screenContent = parsed.screen_content || '—ñ–Ω—à–∏–π –≤–º—ñ—Å—Ç';
                        return {
                            visible: false,
                            message: `–ù–µ –±–∞—á—É "${objectName}" –Ω–∞ –µ–∫—Ä–∞–Ω—ñ. –í–∏–¥–Ω–æ: ${screenContent}`
                        };
                    }
                }
            } catch (parseErr) {
                console.warn('[GRISHA VISION] Could not parse visibility JSON, analyzing text:', response.analysis);
            }

            // Fallback: analyze text response
            const analysisLower = response.analysis.toLowerCase();
            const positiveIndicators = ['–±–∞—á—É', 'yes', 'visible', '–≤—ñ–¥–∫—Ä–∏—Ç–æ', 'opened', 'present'];
            const negativeIndicators = ['–Ω–µ –±–∞—á—É', 'no', 'not visible', '–∑–∞–∫—Ä–∏—Ç–æ', 'hidden', 'absent', 'missing'];

            const hasPositive = positiveIndicators.some(ind => analysisLower.includes(ind));
            const hasNegative = negativeIndicators.some(ind => analysisLower.includes(ind));

            if (hasNegative || !hasPositive) {
                return {
                    visible: false,
                    message: `–ù–µ –±–∞—á—É "${objectName}" –Ω–∞ –µ–∫—Ä–∞–Ω—ñ. ${response.analysis.slice(0, 100)}`
                };
            }

            return {
                visible: true,
                message: `–ë–∞—á—É "${objectName}". ${response.analysis.slice(0, 100)}`
            };

        } catch (error: any) {
            console.error('[GRISHA VISION] Visibility check failed:', error);
            return {
                visible: false,
                message: `–ü–æ–º–∏–ª–∫–∞ –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –≤–∏–¥–∏–º–æ—Å—Ç—ñ: ${error.message}`
            };
        }
    }

    /**
     * Private: On-Demand Verification Logic
     * NOW WITH VISIBILITY CHECK FIRST AND GLOBAL CONTEXT
     */
    private async verifyStepOnDemand(stepAction: string, stepDetails?: string, globalContext?: string, targetApp?: string): Promise<VisionObservationResult> {
        try {
            const base64Image = await this.captureFrame();
            if (!base64Image) {
                return this.errorResult('–ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞—Ö–æ–ø–∏—Ç–∏ –µ–∫—Ä–∞–Ω');
            }

            // STEP 1: Check if object is visible
            console.log('[GRISHA VISION] üëÅÔ∏è Checking object visibility first...');
            const visibilityCheck = await this.checkObjectVisibility(stepAction, base64Image, targetApp);

            if (!visibilityCheck.visible) {
                console.warn(`[GRISHA VISION] ‚ö†Ô∏è Object not visible: ${visibilityCheck.message}`);
                const result: VisionObservationResult = {
                    type: 'alert',
                    message: visibilityCheck.message,
                    verified: false,
                    confidence: 0.9, // High confidence in "not seeing"
                    timestamp: Date.now(),
                    mode: 'on-demand'
                };
                this.emit('observation', result);
                return result;
            }

            console.log(`[GRISHA VISION] ‚úÖ Object visible: ${visibilityCheck.message}`);

            // STEP 2: Verify the action was completed AND matches Goal
            const router = getProviderRouter();

            const contextPrompt = globalContext
                ? `–ì–õ–û–ë–ê–õ–¨–ù–ê –ú–ï–¢–ê –ö–û–†–ò–°–¢–£–í–ê–ß–ê: "${globalContext}".\n–ü–µ—Ä–µ–≤—ñ—Ä, —á–∏ –∫—Ä–æ–∫ –Ω–∞–±–ª–∏–∂–∞—î –Ω–∞—Å –¥–æ —Ü—ñ—î—ó –º–µ—Ç–∏.\n\n`
                : '';

            const targetPrompt = targetApp
                ? `–¶I–õ–¨–û–í–ê –ü–†–û–ì–†–ê–ú–ê: "${targetApp}" (–í—ñ–∫–Ω–æ –º–∞—î –±—É—Ç–∏ –∞–∫—Ç–∏–≤–Ω–∏–º)\n`
                : '';

            const response = await router.analyzeVision({
                image: base64Image,
                mimeType: 'image/jpeg',
                taskContext: stepAction,
                prompt: `–û–±'—î–∫—Ç –ø—ñ–¥—Ç–≤–µ—Ä–¥–∂–µ–Ω–æ –≤–∏–¥–∏–º–∏–º: "${visibilityCheck.message}".

${contextPrompt}${targetPrompt}–ó–∞–≤–¥–∞–Ω–Ω—è –ö—Ä–æ–∫—É: "${stepAction}". ${stepDetails || ''}

–ü–ï–†–ï–í–Ü–†–ö–ê:
1. –ß–∏ –≤–∏–∫–æ–Ω–∞–Ω–æ —Ü—é –¥—ñ—é —É—Å–ø—ñ—à–Ω–æ?
2. –Ø–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç —Ç–∏ –±–∞—á–∏—à? (—á–∏—Å–ª–∞, —Ç–µ–∫—Å—Ç, —Å—Ç–∞–Ω –≤—ñ–∫–Ω–∞).
3. –ß–∏ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î —Ü–µ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –æ—á—ñ–∫—É–≤–∞–Ω–Ω—è–º –≥–ª–æ–±–∞–ª—å–Ω–æ—ó –º–µ—Ç–∏ (—è–∫—â–æ –∑–∞–¥–∞–Ω–∞)?

–Ø–∫—â–æ –¥—ñ—è –≤–∏–∫–æ–Ω–∞–Ω–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ - –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–π "–í–ï–†–ò–§–Ü–ö–û–í–ê–ù–û: [–¥–µ—Ç–∞–ª—ñ]".
–Ø–∫—â–æ —î –ø–æ–º–∏–ª–∫–∞ –∞–±–æ –Ω–µ–≤—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å –º–µ—Ç—ñ - –≤—ñ–¥–ø–æ–≤—ñ–¥–∞–π "–ü–û–ú–ò–õ–ö–ê: [–ø—Ä–∏—á–∏–Ω–∞]. –ö–û–†–ï–ö–¶–Ü–Ø: [—â–æ —Å–∞–º–µ —Ç—Ä–µ–±–∞ –∑—Ä–æ–±–∏—Ç–∏ —ñ–Ω–∞–∫—à–µ?]".
–ù–∞–ø—Ä–∏–∫–ª–∞–¥: "–ü–û–ú–ò–õ–ö–ê: –í–≤–µ–¥–µ–Ω–æ 3 –∑–∞–º—ñ—Å—Ç—å 5. –ö–û–†–ï–ö–¶–Ü–Ø: –ù–∞—Ç–∏—Å–Ω–∏ Backspace —ñ –≤–≤–µ–¥–∏ 5."`
            });

            this.frameCount++;

            const result: VisionObservationResult = {
                type: response.verified ? 'verification' : 'alert',
                message: response.analysis,
                verified: response.verified,
                confidence: response.confidence,
                anomalies: response.anomalies,
                timestamp: Date.now(),
                mode: 'on-demand'
            };

            this.emit('observation', result);
            console.log(`[GRISHA VISION] ${response.verified ? '‚úÖ' : '‚ö†Ô∏è'} Step verified (On-Demand): ${response.analysis.slice(0, 100)}`);

            return result;

        } catch (error: any) {
            console.error('[GRISHA VISION] Verification failed:', error);
            return this.errorResult(`–ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É: ${error.message}`);
        }
    }

    /**
     * Capture a single frame from selected source or screen
     */
    async captureFrame(overrideSourceId?: string): Promise<string | null> {
        try {
            const targetId = overrideSourceId || this.selectedSourceId;

            // Always fetch fresh sources to handle newly opened windows
            const sources = await desktopCapturer.getSources({
                types: ['window', 'screen'],
                thumbnailSize: { width: 1280, height: 720 }
            });

            // Emit sources update for UI
            this.emit('sources_updated', sources.map(s => ({
                id: s.id,
                name: s.name,
                thumbnail: s.thumbnail.toDataURL(),
                isScreen: s.id.startsWith('screen:')
            })));

            if (targetId) {
                // Try to find the selected source
                let source = sources.find(s => s.id === targetId);

                // If not found by ID, try by name (window IDs can change)
                if (!source && this.selectedSourceName) {
                    source = sources.find(s =>
                        s.name.toLowerCase().includes(this.selectedSourceName!.toLowerCase())
                    );
                    if (source && source.id !== targetId) {
                        console.log(`[GRISHA VISION] üîÑ Source ID changed for "${this.selectedSourceName}": ${targetId} -> ${source.id}`);
                        this.selectedSourceId = source.id;
                    }
                }

                if (source) {
                    const jpegBuffer = source.thumbnail.toJPEG(85);
                    return jpegBuffer.toString('base64');
                }
            }

            // Fallback to full screen (first screen)
            const screenSources = sources.filter(s => s.id.startsWith('screen:'));

            if (screenSources.length > 0) {
                const jpegBuffer = screenSources[0].thumbnail.toJPEG(85);
                return jpegBuffer.toString('base64');
            }

            return null;
        } catch (e) {
            console.error('[GRISHA VISION] Capture failed:', e);
            return null;
        }
    }

    // ==================== PRIVATE METHODS ====================

    /**
     * Start Live observation (Gemini Live streaming)
     */
    private async startLiveObservation(taskDescription?: string) {
        if (this.geminiLive && !this.geminiLive.isConnected) {
            try {
                await this.geminiLive.connect();
                await new Promise(resolve => setTimeout(resolve, 500));
            } catch (e) {
                console.error('[GRISHA VISION] Failed to connect Gemini Live:', e);
            }
        }

        if (this.geminiLive?.sendText) {
            this.geminiLive.sendText("–°–∏—Å—Ç–µ–º–∞: –ü–æ—á–∏–Ω–∞—î–º–æ —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è. –û–ø–∏—à–∏ —â–æ –±–∞—á–∏—à –Ω–∞ –µ–∫—Ä–∞–Ω—ñ.");
        }

        await this.captureAndSendLiveFrame();

        this.captureInterval = setInterval(async () => {
            if (this.isSpeaking || this.isPaused) return;
            await this.captureAndSendLiveFrame();
        }, this.captureIntervalMs);

        this.emitResult('observation', `Live —Å–ø–æ—Å—Ç–µ—Ä–µ–∂–µ–Ω–Ω—è —Ä–æ–∑–ø–æ—á–∞—Ç–æ (${this.captureIntervalMs}ms). ${taskDescription || '–ú–æ–Ω—ñ—Ç–æ—Ä—é –≤–∏–∫–æ–Ω–∞–Ω–Ω—è...'}`);
    }

    /**
     * Capture and send frame to Gemini Live
     */
    private async captureAndSendLiveFrame() {
        try {
            const base64 = await this.captureFrame();
            if (base64 && this.geminiLive?.isConnected) {
                this.geminiLive.sendVideoFrame(base64);
                this.frameCount++;
            }
        } catch (e) {
            console.error('[GRISHA VISION] Live capture failed:', e);
        }
    }

    /**
     * Notify Gemini Live about an action (Live mode)
     */
    private async notifyActionLive(action: string, details: string) {
        if (this.geminiLive?.sendText) {
            console.log(`[GRISHA VISION] üó£Ô∏è Prompting verification: ${action}`);
            this.geminiLive.sendText(`–°–∏—Å—Ç–µ–º–∞: –í–∏–∫–æ–Ω–∞–Ω–æ –¥—ñ—é "${action}" (${details}). –ü—ñ–¥—Ç–≤–µ—Ä–¥—å —Å–ª–æ–≤–æ–º "–í–∏–∫–æ–Ω–∞–Ω–æ" –∞–±–æ –ø–æ–≤—ñ–¥–æ–º –ø—Ä–æ –ø–æ–º–∏–ª–∫—É.`);

            // Also send a fresh frame
            await this.captureAndSendLiveFrame();
        }
    }

    /**
     * Process response from Gemini Live
     */
    private processLiveResponse(text: string) {
        const lowerText = text.toLowerCase();
        let resultType: 'confirmation' | 'alert' | 'observation' = 'observation';

        if (lowerText.includes('alert') || lowerText.includes('–ø–æ–º–∏–ª–∫–∞') || lowerText.includes('error') || lowerText.includes('–Ω–µ –≤–∏–∫–æ–Ω–∞–Ω–æ')) {
            resultType = 'alert';
        } else if (lowerText.includes('ok') || lowerText.includes('–≤–∏–∫–æ–Ω–∞–Ω–æ') || lowerText.includes('stable') || lowerText.includes('done')) {
            resultType = 'confirmation';
        }

        const result: VisionObservationResult = {
            type: resultType,
            message: text,
            verified: resultType === 'confirmation',
            timestamp: Date.now(),
            mode: 'live'
        };

        console.log(`[GRISHA VISION] üîç ${resultType.toUpperCase()}: ${text}`);
        this.emit('observation', result);
    }

    /**
     * Helper: emit observation result
     */
    private emitResult(type: VisionObservationResult['type'], message: string, verified?: boolean) {
        this.emit('observation', {
            type,
            message,
            verified,
            timestamp: Date.now(),
            mode: this.mode
        } as VisionObservationResult);
    }

    /**
     * Helper: create error result
     */
    private errorResult(message: string): VisionObservationResult {
        return {
            type: 'alert',
            message,
            verified: false,
            timestamp: Date.now(),
            mode: this.mode
        };
    }

    get isActive(): boolean {
        return this.isObserving;
    }
}

// Singleton instance
let visionServiceInstance: GrishaVisionService | null = null;

export function getGrishaVisionService(): GrishaVisionService {
    if (!visionServiceInstance) {
        visionServiceInstance = new GrishaVisionService();
    }
    return visionServiceInstance;
}
